{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2rrYNrvYqdd"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import itertools  \n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgqIgBQCJ4K2"
   },
   "source": [
    "# Learning Long Time Dependencies \n",
    "## Generate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3RK4_uWYztq"
   },
   "outputs": [],
   "source": [
    "#question 4 generate data.\n",
    "def one_hot(num):\n",
    "  return [1 if i==num else 0 for i in range(101)] #p = 100 so p+1 dimension vector \n",
    "# two kinds of seqs. (x,a,x) and (y,a,y)\n",
    "# (x,a,x) sequence \n",
    "\n",
    "\n",
    "def seq_xax():\n",
    "  #generate x\n",
    "  p = 100\n",
    "  seq = [] \n",
    "  for i in range(100): # x \n",
    "    seq.append(one_hot(i))\n",
    "  curr = random.randint(1, p-1)\n",
    "  seq.append(one_hot(curr))\n",
    "  prev = curr\n",
    "  for i in range(p-2): # ai1,....., aip-1\n",
    "    curr = random.randint(prev, p-1)\n",
    "    seq.append(one_hot(curr))\n",
    "    prev = curr\n",
    "  for i in range(100): # x \n",
    "    seq.append(one_hot(i))\n",
    "  return seq\n",
    "def seq_yay():\n",
    "  p = 100\n",
    "  seq = []\n",
    "  seq.append(one_hot(p+1)) # y\n",
    "  curr = random.randint(1, p-1)\n",
    "  seq.append(one_hot(curr))\n",
    "  prev = curr\n",
    "  for i in range(p-2): # ai1,....., aip-1\n",
    "    curr = random.randint(prev, p-1)\n",
    "    seq.append(one_hot(curr))\n",
    "    prev = curr\n",
    "  seq.append(one_hot(p+1)) # y\n",
    "  return seq\n",
    "\n",
    "def gen_data(num_data):\n",
    "  train_data = []\n",
    "  for i in range(num_data):\n",
    "    if random.random() > 0.5:\n",
    "      curr_seq = seq_xax()\n",
    "      for symbol in curr_seq:\n",
    "        train_data.append(symbol)\n",
    "    else:\n",
    "      curr_seq = seq_yay()\n",
    "      for symbol in curr_seq:\n",
    "        train_data.append(symbol)\n",
    "  return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ezdWlI5eY2qj",
    "outputId": "47a3f10b-37c9-4d0e-9272-c3a4fe074dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198, 101)\n"
     ]
    }
   ],
   "source": [
    "train_data = gen_data(10)\n",
    "test_data = gen_data(10)\n",
    "train_data = np.array(train_data)\n",
    "print((np.shape(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvK0XCXjKCH5"
   },
   "source": [
    "## Transform Data \n",
    "- We do this so as to have 100 RNNCells in each layer.  \n",
    "- Also, so that a sequence as destined target to achieve i.e the next symbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GJKpisU2Y4di",
    "outputId": "e7721404-0c7d-47b5-814e-508e83f3854b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2098, 100, 101])\n",
      "torch.Size([2098, 1, 101])\n"
     ]
    }
   ],
   "source": [
    "def transform_data(arr, seq_len):\n",
    "    x, y = [], []\n",
    "    for i in range(len(arr) - seq_len):\n",
    "        x_i = arr[i : i + seq_len]\n",
    "        y_i = arr[i + seq_len: i + seq_len + 1]\n",
    "        # print(np.shape(y_i))\n",
    "        x.append(np.array(x_i))\n",
    "        y.append(np.array(y_i).astype('float64'))\n",
    "    x_arr = np.array(x)\n",
    "    y_arr = np.array(y)\n",
    "    x_var = Variable(torch.from_numpy(x_arr).float())\n",
    "    y_var = Variable(torch.from_numpy(y_arr).float())\n",
    "    return x_var, y_var\n",
    "\n",
    "seq_len = 100 \n",
    "train_input, train_target = transform_data(train_data, seq_len)\n",
    "test_input, test_target = transform_data(test_data, seq_len)\n",
    "print(np.shape(train_input))\n",
    "print(np.shape((train_target)))\n",
    "# print(train_target[:5])\n",
    "# # print(train_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ar9Y0XWTKdGD"
   },
   "source": [
    "## LSTM\n",
    "### LSTM Architecture  \n",
    "- The architecture has 3 LSTM layers stacked on top of each other.\n",
    "- Then we have a linear fully connected (FC) layer.  \n",
    "- We have a softmax layer as an activation function before the output layer.\n",
    "- We, further, make sure that the input size and the output size is 101 (our one-hot vector size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qp6dXnz5Y6nT"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=101, hidden_layer_size=150, output_size=101, num_layers = 3):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(3,1,self.hidden_layer_size),\n",
    "                            torch.zeros(3,1,self.hidden_layer_size))\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.soft(self.linear(lstm_out.view(len(input_seq), -1)))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j27hMqrtKuPY"
   },
   "source": [
    "- We define which optimiser to use. Here, it is Adam \n",
    "- Learning rate is also defined. Here, it is $2*10^{-8}$ \n",
    "- We also define which loss function to use. Here, we used MSE loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MH1BWfuY8qk"
   },
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2*10e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMpDltVNMLKi"
   },
   "source": [
    "### Training the Model \n",
    "- We run it for 35 epochs. In each epoch, we go through all the sequences one by one. \n",
    "- Then, we compute gradients and perform a backpropagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "colab_type": "code",
    "id": "lCSLCYKDY-YA",
    "outputId": "2c0e3d68-8f6f-4a9c-c8ef-aaefaa3d8849"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([1, 101])) that is different to the input size (torch.Size([101])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.00980381\n",
      "epoch:   1 loss: 0.00980182\n",
      "epoch:   2 loss: 0.00979977\n",
      "epoch:   3 loss: 0.00979764\n",
      "epoch:   4 loss: 0.00979541\n",
      "epoch:   5 loss: 0.00979308\n",
      "epoch:   6 loss: 0.00979062\n",
      "epoch:   7 loss: 0.00978801\n",
      "epoch:   8 loss: 0.00978522\n",
      "epoch:   9 loss: 0.00978221\n",
      "epoch:  10 loss: 0.00977895\n",
      "epoch:  11 loss: 0.00977536\n",
      "epoch:  12 loss: 0.00977140\n",
      "epoch:  13 loss: 0.00976697\n",
      "epoch:  14 loss: 0.00976194\n",
      "epoch:  15 loss: 0.00975619\n",
      "epoch:  16 loss: 0.00974949\n",
      "epoch:  17 loss: 0.00974158\n",
      "epoch:  18 loss: 0.00973206\n",
      "epoch:  19 loss: 0.00972034\n",
      "epoch:  20 loss: 0.00970558\n",
      "epoch:  21 loss: 0.00968642\n",
      "epoch:  22 loss: 0.00966067\n",
      "epoch:  23 loss: 0.00962465\n",
      "epoch:  24 loss: 0.00957188\n",
      "epoch:  25 loss: 0.00949079\n",
      "epoch:  26 loss: 0.00936081\n",
      "epoch:  27 loss: 0.00914906\n",
      "epoch:  28 loss: 0.00881456\n",
      "epoch:  29 loss: 0.00832882\n",
      "epoch:  30 loss: 0.00770760\n",
      "epoch:  31 loss: 0.00702174\n",
      "epoch:  32 loss: 0.00636293\n",
      "epoch:  33 loss: 0.00579880\n",
      "epoch:  34 loss: 0.00535443\n"
     ]
    }
   ],
   "source": [
    "epochs = 35\n",
    "loss_epoch = []\n",
    "index = []\n",
    "for i in range(epochs): \n",
    "    index.append(i)\n",
    "    for seq, labels in zip(train_input, train_target):\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(3, 1, model.hidden_layer_size),\n",
    "                             torch.zeros(3, 1, model.hidden_layer_size))\n",
    "        # print(np.shape(seq))\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_epoch.append(single_loss.item()) # Each epoch has 10 sequences. So printing after epoch for better representation. Talk abotu multi-dirac \n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "437wERT_MyzH"
   },
   "source": [
    "### Our Model loss curve\n",
    "The below plot shows epoch vs loss curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "bfik57j5IY-N",
    "outputId": "e6d8753e-4f6f-4380-af0b-a8fe3cd4f3d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f51c56c54a8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfvklEQVR4nO3de5hU9Z3n8fe3qvpCNwgNdNMILRdBmgYjaosaL1GQCJmsmMS4mDUxWRM3OzGXyc6za/bZmXWdnZ3NPjNxZya31Rg10QQdkyjJRI0KXmIi0ESMXLUFBFouDc29r1X13T/qNCnbprukL6cun9fz9FOnfud3Tn3PeaA/Xb9T9Tvm7oiISOGJhF2AiIiEQwEgIlKgFAAiIgVKASAiUqAUACIiBUoBICJSoDIKADNbbGZbzazRzO7oZX2JmT0SrF9tZlOD9nFmtsrMjpvZt3tsc6GZvR5s809mZoNxQCIikpl+A8DMosB3gCVAHXCTmdX16HYrcMjdZwB3A98M2tuBvwL+spddfw/4AjAz+Fl8OgcgIiKnJ5ZBn/lAo7tvAzCz5cBSYFNan6XAncHyY8C3zczc/QTwWzObkb5DM5sInOHurwTPfwRcDzzZVyHjx4/3qVOnZlCyiIgArFu37oC7V/a2LpMAmATsSnu+G7j4VH3cPW5mR4BxwIE+9rm7xz4n9VfI1KlTaWhoyKBkEREBMLO3T7Uu6y8Cm9ltZtZgZg3Nzc1hlyMikjcyCYAmoCbt+eSgrdc+ZhYDRgMH+9nn5H72CYC73+Pu9e5eX1nZ67sYERE5DZkEwFpgpplNM7NiYBmwokefFcAtwfINwErvY5Y5d98DHDWzS4JP/3wGeOJ9Vy8iIqet32sAwZj+7cDTQBT4obtvNLO7gAZ3XwHcB/zYzBqBFlIhAYCZ7QDOAIrN7Hrgw+6+Cfhz4AFgBKmLv31eABYRkcFluTQddH19vesisIhI5sxsnbvX97Yu6y8Ci4jI0FAAiIgUqEy+B5Dz/um5N4knnagZEYNIxIiYEY1AxLqXe6wzwwyikdQ6C9q6+0Stuz3oY5Zq797PyX2mP/beHolwcn/p+06vSzNliMhgK4gA+P4Lb9HamQi7jAGJGMQikZNh0R023WHxrp+0togZseip+8ZOPkaIvOu5ved5NBJ51/NYNO158BpFkcjJ57FIJHhM9S062TdCUbC+KPqn/RRFU/2LgvVFQbvCT2RoFEQAbLprMe6OOyTcSbqTTELSPfU86SSSTtLBu9uctPbUT6J7m6SnPaa1Jd+7bcI9tc8k73qtU7V37+tPbWnru9f17Ju2z/R18cSf+sTT+nXGkyf7xhPv3TbVP/mu7eKJd/cZTulhUByLpIIjZhRHIxRFI5TEUo/FaY/FPR5LYsHzWPfz6Mn2kliE0qLoKR9Li6KMCJ5HIgojyR8FEQCQGkIxgwj6DzxQ6WEUTzqJRCow4sHzeCJYTjhdieTJQIknUuu7Et3LSbrSH4Plznhq+654kq6T/VN9uhJJuhKpPl1BmKW3nehMnGzrjKd+OuKpts5gHwNRWhRhRBAIpcXRk8sjiqOMLIlRVhyjvCSaeiyOUlYSY2TwfGRJjFGlMUaVFjGqNMbI0hgji2MKFQlNwQSADJ5IxIhgFEXDruT9SyadzkSSjiAYOrpSy+1diVRb8Nie9tjelaCtK0lb93Jngrau1E97Z4LWzgTH2uPsO9rOiY4EJzrjtHYk6Ewk+63HDEYW/ykYRo8oYkxZ6qeirJgxZcVUlHW3FVNRVsy4kcWMLStWcMiAKQCkoEQiRmkkNawDRUP6Wp3xJG2dqUA40RHneEecY+3dP12px4605fYuDrd2sbOlldd2d3KotYvOeO8hEo0Y40cWUzmqhKpRpVSOLKHqjBIqR5VQObKEM8eMoGZsGRVlRbqGIqekABAZIt3XG0aXnV7QuDttXQkOt3ZxqLXz5OPB453sP9ZO87EOmo91sO9oOxuajnDgeAc9L8+UF0eZXFHG5IpUIEyuGMHkijJqxo5g+viRjCjOwbdxMmgUACJZyswoK05dVzhzzIh++yeSTsuJVDi8c7idXS2t7DrUyu5DbexqaWX19haOd8TT9g/TxpVTO3EUtdVnUFudepxcMULDSwVCASCSJ6IRSw0BjSphzpmj37Pe3TnS1sWuljZ2trTyxr5jbNl7lI3vHOXXr+892a+8OMqs6lHUTjyD+ikVXDZjPBPOKB3OQ5FhormARIQTHfEgEI6xZc9RNu89xuY9RznWnnrHcHZlOZfNGM8Hzx7PpdPHnfawlgy/vuYCUgCISK+SSWfTnqP87q0DvNx4kDXbW2jrShAxmDtpNB88ezyXzxjPxdPHUhTVrDLZSgEgIgPWGU/y6s5DvPzWQX7XeID1uw4TTzpVo0q4sb6GZfNrmFxRFnaZ0oMCQEQG3YmOOL9tPMAja3exaut+AD50TiWfmn8WC2qriOldQVZQAIjIkGo63MYja3ayfO0u9h/roPqMUm68qIZlF9Vk9AkmGToKABEZFvFEkue27Ofh1Tt56c1mDLh6VhV/ee0sZk88I+zyCpICQESG3a6WVn66Zic/XbOTY+1x/uNVZ3P7ghmUxPTls+GkO4KJyLCrGVvGf15cy8r/dBXXnXcm/7yykY/840s07GgJuzQJKABEZEhVlBfzrX87jwc+dxHtXUk++f9+z18/seFd30qWcCgARGRYXDWriqf/4kpuuXQqP37lbT78rRdYtWV/2GUVNAWAiAybkSUx7rxuDo998YOUlcT43ANr+eryVzl4vCPs0gqSAkBEht2FUyr4169czlcWzuTXr+9h0d0vsu7tQ2GXVXAUACISipJYlK8vOodfffkKRpXG+Oz9a9jQdCTssgqKAkBEQjWrehQPf/5iRpXE+MwP1/DmvmNhl1QwFAAiErrJFWU8/IVLiJhx832r2XmwNeySCoICQESywrTx5Tz8+YvpiCf51A9eYc+RtrBLynsKABHJGrOqR/Gjfz+fw61d/LsfrOaAPh00pBQAIpJVPjB5DPd/7iLeOdzGzT9YzeHWzrBLylsKABHJOhdNHcu9n6lnW/MJbrl/rb41PEQUACKSla6YWcm3P3U+G5qOcOsDa2nrTIRdUt5RAIhI1vrwnGq+deN5rNnRwhcfWkdnPBl2SXlFASAiWW3pvEn83cfO5YU3mvnBb7eFXU5eUQCISNZbNv8srp0zgX9+rpGmw/p46GBRAIhITvirj9bhOH/zy01hl5I3FAAikhMmV5Tx5QUzeWrjXp7fqmmkB0NGAWBmi81sq5k1mtkdvawvMbNHgvWrzWxq2rpvBO1bzezatPavmtkGM9toZl8bjIMRkfz2+SumMX18OXeu2EhHXJ8KGqh+A8DMosB3gCVAHXCTmdX16HYrcMjdZwB3A98Mtq0DlgFzgMXAd80samZzgS8A84HzgI+a2YzBOSQRyVclsSh3XjeHHQdbufdFXRAeqEzeAcwHGt19m7t3AsuBpT36LAUeDJYfAxaamQXty929w923A43B/mYDq9291d3jwAvAxwd+OCKS7648p5KPnFvNt1c1sqtFk8YNRCYBMAnYlfZ8d9DWa5/gF/oRYFwf224ArjCzcWZWBnwEqOntxc3sNjNrMLOG5ubmDMoVkXz33/6sDsO461e6IDwQoVwEdvfNpIaJfgM8BawHeh3Qc/d73L3e3esrKyuHsUoRyVZnjhnBVxbO5JlN+1i5ZV/Y5eSsTAKgiXf/dT45aOu1j5nFgNHAwb62dff73P1Cd78SOAS8cToHICKF6dbLp3F2ZTl3rthEe5cuCJ+OTAJgLTDTzKaZWTGpi7orevRZAdwSLN8ArHR3D9qXBZ8SmgbMBNYAmFlV8HgWqfH/nwz0YESkcBTHIty1dC47W1r5/gtvhV1OTor118Hd42Z2O/A0EAV+6O4bzewuoMHdVwD3AT82s0aghVRIEPR7FNgExIEvuXt3VP/MzMYBXUH74cE+OBHJb5fNGM9HPzCR7z7/Fh8/fzJnjSsLu6ScYqk/1HNDfX29NzQ0hF2GiGSRvUfaWfAPz3Pp9HHc99mLwi4n65jZOnev722dvgksIjmtenQpX7tmJs9t2c+zm3RB+P1QAIhIzvvcZdOYWTWSO3+5UReE3wcFgIjkvKJohL/+N3XsPtTGivXvhF1OzlAAiEheuHzGeM6ZMJIfvbKDXLq2GSYFgIjkBTPj05dMYUPTUV7bfSTscnKCAkBE8sbHLphMeXGUH//+7bBLyQkKABHJGyNLYnz8gsn88o/v0HKiM+xysp4CQETyys2XTKEznuRfGnb137nAKQBEJK/Mqh7F/GljeWj12ySTuhjcFwWAiOSdT18yhV0tbbzwpqaQ74sCQETyzrVzqqkcVcJDuhjcJwWAiOSd4liEmy6qYeXW/bprWB8UACKSl266+CwiZjy8emfYpWQtBYCI5KWJo0dwzewqHm3YpfmBTkEBICJ569OXTKXlRCdPbtgTdilZSQEgInnrshnjmF5Zzo90MbhXCgARyVtmxs0XT+HVnYfZ0KT5gXpSAIhIXvvEhZMpLYrw0Ct6F9CTAkBE8troEUVcP28Sj69v4khbV9jlZBUFgIjkvZsvmUJ7V5KfrdsddilZRQEgInlv7qTRnH/WGB56RfMDpVMAiEhB+MylU9h24AS/e+tg2KVkDQWAiBSEJXMnMra8mB+/siPsUrKGAkBECkJpUZQb62t4ZtM+9h1tD7ucrKAAEJGCccOFk0g6PLVhb9ilZAUFgIgUjBlVo5hRNVJTQwQUACJSUJbMrWbN9hYOHu8Iu5TQKQBEpKAsnltN0uE3m/aFXUroFAAiUlDqJp7BWWPLeFLXARQAIlJYzIwlc6v5XeMBjrQW9tQQCgARKTiL51YTTzrPbi7sYSAFgIgUnPMmj2Hi6NKCHwZSAIhIwYlEjGvnVPPim80c74iHXU5oFAAiUpCWzK2mM55k1Zb9YZcSGgWAiBSk+qljGT+yuKC/FZxRAJjZYjPbamaNZnZHL+tLzOyRYP1qM5uatu4bQftWM7s2rf0vzGyjmW0ws5+aWelgHJCISCaiEePDc6pZtXU/7V2JsMsJRb8BYGZR4DvAEqAOuMnM6np0uxU45O4zgLuBbwbb1gHLgDnAYuC7ZhY1s0nAV4B6d58LRIN+IiLD5iNzJ9LameCFN5rDLiUUmbwDmA80uvs2d+8ElgNLe/RZCjwYLD8GLDQzC9qXu3uHu28HGoP9AcSAEWYWA8qAdwZ2KCIi78/F08cypqyoYIeBMgmAScCutOe7g7Ze+7h7HDgCjDvVtu7eBPw9sBPYAxxx99/09uJmdpuZNZhZQ3NzYaa0iAyNomiERbMn8OzmfXTGk2GXM+xCuQhsZhWk3h1MA84Eys3s5t76uvs97l7v7vWVlZXDWaaIFIAl51ZzrD3Oy28dCLuUYZdJADQBNWnPJwdtvfYJhnRGAwf72PYaYLu7N7t7F/Bz4IOncwAiIgNx2YzxjCqJ8eTrhTdFdCYBsBaYaWbTzKyY1MXaFT36rABuCZZvAFa6uwfty4JPCU0DZgJrSA39XGJmZcG1goXA5oEfjojI+1MSi7JgdhXPbNpHPFFYw0D9BkAwpn878DSpX9KPuvtGM7vLzK4Lut0HjDOzRuDrwB3BthuBR4FNwFPAl9w94e6rSV0s/gPwelDHPYN6ZCIiGVoyt5pDrV2s3t4SdinDylJ/qOeG+vp6b2hoCLsMEckzbZ0JLvibZ/jEhZP4n9efG3Y5g8rM1rl7fW/r9E1gESl4I4qjXDWrkqc37iOZzJ0/igdKASAiQmqK6OZjHazbeSjsUoaNAkBEBFhQW0VxNMKTrxfOl8IUACIiwKjSIq6YOZ6nN+4ll66NDoQCQEQksHhuNU2H2/jj7iNhlzIsFAAiIoFFdROIRaxg7hSmABARCYwpK+bSs8fx1IY9BTEMpAAQEUmzeG41Ow628ub+42GXMuQUACIiaRbUVgGwsgBuFakAEBFJM3H0CGZPPEMBICJSiBbWVrHu7UMcae0Ku5QhpQAQEenh6toqEknnhTfz+yZUCgARkR7m1YxhbHkxq/J8GEgBICLSQzRifOicSp7fup9EHk8OpwAQEenF1bVVHGrtYv2uw2GXMmQUACIivfjQzEqiEWPlln1hlzJkFAAiIr0YXVbEhVMqWLklfy8EKwBERE5hQW0Vm/ccZc+RtrBLGRIKABGRU+j+VvCqPH0XoAAQETmFmVUjmTRmRN5eB1AAiIicgpmxcHYVLzcepL0rEXY5g04BICLSh6trq2jrSvDKtoNhlzLoFAAiIn24dPo4SosiefmtYAWAiEgfSouiXHb2eFZu3Z93N4lRAIiI9OPq2ip2tbTRmGc3iVEAiIj0I19vEqMAEBHpx5ljRlBbPUoBICJSiBbUVtHw9iGOtOXPTWIUACIiGVgQ3CTmpTy6SYwCQEQkA+efVcGYsiJWbs6fYSAFgIhIBqIR46pzKnn+jea8uUmMAkBEJENX11bRcqKT13bnx01iFAAiIhn60DmVRIy8+VawAkBEJENjyoqDm8QoAERECs7VtVVsfOcoe4+0h13KgGUUAGa22My2mlmjmd3Ry/oSM3skWL/azKamrftG0L7VzK4N2maZ2fq0n6Nm9rXBOigRkaGysHYCAKu25v67gH4DwMyiwHeAJUAdcJOZ1fXoditwyN1nAHcD3wy2rQOWAXOAxcB3zSzq7lvdfZ67zwMuBFqBXwzSMYmIDJlzJnTfJKYAAgCYDzS6+zZ37wSWA0t79FkKPBgsPwYsNDML2pe7e4e7bwcag/2lWwi85e5vn+5BiIgMFzPj6tpKXm48kPM3ickkACYBu9Ke7w7aeu3j7nHgCDAuw22XAT/NvGQRkXAtnD2B1s4Ev8/xm8SEehHYzIqB64B/6aPPbWbWYGYNzc358xVsEcldl04fR1lxlGc35fa9gjMJgCagJu355KCt1z5mFgNGAwcz2HYJ8Ad3P+VZdPd73L3e3esrKyszKFdEZGiVFkW5cmYlz27el9M3ickkANYCM81sWvAX+zJgRY8+K4BbguUbgJWeOisrgGXBp4SmATOBNWnb3YSGf0QkBy2qm8C+ox283nQk7FJOW78BEIzp3w48DWwGHnX3jWZ2l5ldF3S7DxhnZo3A14E7gm03Ao8Cm4CngC+5ewLAzMqBRcDPB/eQRESG3tW1VUSMnB4Gslx6+1JfX+8NDQ1hlyEiAsCN3/89xzriPPnVK8Iu5ZTMbJ271/e2Tt8EFhE5TYvqJrB5z1F2tbSGXcppUQCIiJyma+pS3wp+bnNuDgMpAERETtO08eWcXVnOszl6kxgFgIjIACyqq+aVbQdz8l7BCgARkQFYVFdFPOm88EbufVFVASAiMgDzaioYV16ckx8HVQCIiAxANGIsqK1i1db9dCWSYZfzvigAREQGaFHdBI61x1mzvSXsUt4XBYCIyABdPnM8JbEIz+TYMJACQERkgMqKY1w+Y3zOTQ6nABARGQSL6iaw+1AbW/YeC7uUjCkAREQGwYLZVUBuTQ6nABARGQRVo0qZVzOGZ3NoWggFgIjIIFlUN4HXdh9h39H2sEvJiAJARGSQLAomh8uVdwEKABGRQTKzaiRnjS3LmesACgARkUFiZlwzewIvv3WQEx3xsMvplwJARGQQLaqbQGc8yUtvZv/kcAoAEZFBVD+1gtEjinhmU/bfI0ABICIyiIqiEa6eVcnKLftIJLP7W8EKABGRQXZN3QQOtXax7u1DYZfSJwWAiMgg+9A5lRRFLes/DqoAEBEZZKNKi7hk+jie2ZTdk8MpAEREhsC1c6rZfuAEm/YcDbuUU1IAiIgMgT87dyKxiPHE+nfCLuWUFAAiIkOgoryYq2ZV8sT6pqz9NJACQERkiCydN4l9RztYve1g2KX0SgEgIjJErpk9gZElMX7xalPYpfRKASAiMkRGFEe5dk41T23YS3tXIuxy3kMBICIyhD52/iSOdcR5bnP2TQ2hABARGUKXnj2OqlElPL4++4aBFAAiIkMoGjGuO+9Mnt+6n8OtnWGX8y4KABGRIXb9+ZPoSjj/+vqesEt5FwWAiMgQm3PmGcyoGskTr2bXl8IUACIiQ8zMuH7emazZ0cLuQ61hl3OSAkBEZBgsnTcJIKumhsgoAMxssZltNbNGM7ujl/UlZvZIsH61mU1NW/eNoH2rmV2b1j7GzB4zsy1mttnMLh2MAxIRyUY1Y8uon1LB4682Zc0Mof0GgJlFge8AS4A64CYzq+vR7VbgkLvPAO4GvhlsWwcsA+YAi4HvBvsD+EfgKXevBc4DNg/8cEREstfS8yfx5v7jWTNDaCbvAOYDje6+zd07geXA0h59lgIPBsuPAQvNzIL25e7e4e7bgUZgvpmNBq4E7gNw9053PzzwwxERyV4fDWYIfTxLpobIJAAmAbvSnu8O2nrt4+5x4Agwro9tpwHNwP1m9qqZ/cDMynt7cTO7zcwazKyhubk5g3JFRLJT9wyhK157JytmCA3rInAMuAD4nrufD5wA3nNtAcDd73H3enevr6ysHM4aRUQG3fXnp2YIfSULZgjNJACagJq055ODtl77mFkMGA0c7GPb3cBud18dtD9GKhBERPJa9wyh2TAMlEkArAVmmtk0MysmdVF3RY8+K4BbguUbgJWeusy9AlgWfEpoGjATWOPue4FdZjYr2GYhsGmAxyIikvVKi6IsnpsdM4T2GwDBmP7twNOkPqnzqLtvNLO7zOy6oNt9wDgzawS+TjCc4+4bgUdJ/XJ/CviSu3cf8ZeBh83sj8A84H8N3mGJiGSv6+dlxwyhli2fR81EfX29NzQ0hF2GiMiAJJLOpX/3HOfVjOHez9QP6WuZ2Tp37/VF9E1gEZFhli0zhCoARERCkA0zhCoARERC0D1DaJifBlIAiIiEwMz4xAWTWbvjEJtDmhpCASAiEpKb5tdQVhzl3pe2hfL6CgARkZCMKSvmxvoaVqx/hz1H2ob99RUAIiIhuvXyaSTdeeB3O4b9tRUAIiIhqhlbxpJzJ/KTV3ZyrL1rWF9bASAiErLbrpjOsY44j6zd1X/nQaQAEBEJ2Xk1Y5g/bSz3v7yDrkRy2F5XASAikgVuu2I6TYfb+PUwfjFMASAikgUW1FZxdmU59760bdjuGawAEBHJApGI8YUrprOh6Si/H6abxSgARESyxPXnT2L8yGLufXF4vhimABARyRKlRVFuuXQqq7Y288a+Y0P+egoAEZEscvMlUygtigzLuwAFgIhIFqkoT00P8fj6JvYfbR/S11IAiIhkmVsvn0Y8OfTTQygARESyzJRx5SyeU81Dr7zNiY74kL2OAkBEJAt94crpHG2P82jD0E0PoQAQEclCF5xVQf2UCu777XbiQzQ9hAJARCRL3XbldHYfauOpjXuHZP8KABGRLHXN7AlMG1/OvS8OzfQQCgARkSwViRh/ftXZfGDyGDrigz8MFBv0PYqIyKD5ZH0Nn6yvGZJ96x2AiEiBUgCIiBQoBYCISIFSAIiIFCgFgIhIgVIAiIgUKAWAiEiBUgCIiBQoG667zw8GM2sG3j7NzccDBwaxnOGQazXnWr2gmodLrtWca/XCqWue4u6VvW2QUwEwEGbW4O71YdfxfuRazblWL6jm4ZJrNedavXB6NWsISESkQCkAREQKVCEFwD1hF3Aacq3mXKsXVPNwybWac61eOI2aC+YagIiIvFshvQMQEZE0eR8AZrbYzLaaWaOZ3RF2PZkwsx1m9rqZrTezhrDr6Y2Z/dDM9pvZhrS2sWb2jJm9GTxWhFljT6eo+U4zawrO9Xoz+0iYNaYzsxozW2Vmm8xso5l9NWjP2vPcR83ZfJ5LzWyNmb0W1Pw/gvZpZrY6+N3xiJkVh11rtz5qfsDMtqed53l97iefh4DMLAq8ASwCdgNrgZvcfVOohfXDzHYA9e6etZ9DNrMrgePAj9x9btD2f4AWd//fQdhWuPt/CbPOdKeo+U7guLv/fZi19cbMJgIT3f0PZjYKWAdcD3yWLD3PfdR8I9l7ng0od/fjZlYE/Bb4KvB14OfuvtzMvg+85u7fC7PWbn3U/EXgV+7+WCb7yfd3APOBRnff5u6dwHJgacg15QV3fxFo6dG8FHgwWH6Q1H/8rHGKmrOWu+9x9z8Ey8eAzcAksvg891Fz1vKU48HTouDHgQVA9y/SbDvPp6r5fcn3AJgE7Ep7vpss/8cYcOA3ZrbOzG4Lu5j3YYK77wmW9wITwizmfbjdzP4YDBFlzXBKOjObCpwPrCZHznOPmiGLz7OZRc1sPbAfeAZ4Czjs7vGgS9b97uhZs7t3n+e/Dc7z3WZW0tc+8j0ActXl7n4BsAT4UjB0kVM8NbaYC+OL3wPOBuYBe4B/CLec9zKzkcDPgK+5+9H0ddl6nnupOavPs7sn3H0eMJnUyEFtyCX1q2fNZjYX+Aap2i8CxgJ9Dg3mewA0Ael3U54ctGU1d28KHvcDvyD1DzIX7AvGgLvHgveHXE+/3H1f8B8pCdxLlp3rYHz3Z8DD7v7zoDmrz3NvNWf7ee7m7oeBVcClwBgziwWrsvZ3R1rNi4MhOHf3DuB++jnP+R4Aa4GZwdX8YmAZsCLkmvpkZuXBxTPMrBz4MLCh762yxgrglmD5FuCJEGvJSPcv0sDHyKJzHVzouw/Y7O7fSluVtef5VDVn+XmuNLMxwfIIUh8a2Uzql+oNQbdsO8+91bwl7Q8DI3XNos/znNefAgIIPm72f4Eo8EN3/9uQS+qTmU0n9Vc/QAz4STbWbGY/Ba4iNQPhPuC/A48DjwJnkZq19UZ3z5qLrqeo+SpSwxIO7AD+Q9r4eqjM7HLgJeB1IBk0/1dSY+pZeZ77qPkmsvc8f4DURd4oqT+KH3X3u4L/i8tJDaW8Ctwc/GUduj5qXglUAgasB76YdrH4vfvJ9wAQEZHe5fsQkIiInIICQESkQCkAREQKlAJARKRAKQBERAqUAkBEpEApAERECpQCQESkQP1/7Fv3hhvridUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(index, loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjsiZSh8NB1s"
   },
   "source": [
    "### Test our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-qgPP_rSizC"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_outputs = []\n",
    "for seq in test_input:\n",
    "  with torch.no_grad():\n",
    "        model.hidden_cell = (torch.zeros(3, 1, model.hidden_layer_size),\n",
    "                              torch.zeros(3, 1, model.hidden_layer_size))\n",
    "        seq = seq.float()\n",
    "        seq= Variable(seq)\n",
    "        y_pred = model(seq)\n",
    "        test_outputs.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Fq_kTjdHYEZE",
    "outputId": "db81793f-9832-4ee9-fd2e-8b608f9d6c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(39)\n"
     ]
    }
   ],
   "source": [
    "# print(test_outputs[:1])\n",
    "_, target = test_outputs[0].max(dim=0)\n",
    "print(target)\n",
    "# print(test_target[:1])\n",
    "print(test_target[0])\n",
    "test = (test_target[0].reshape(-1,))\n",
    "_, target = test.max(dim=0)\n",
    "print(target)\n",
    "# print(test_target.reshape(,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EN1PRyMPQJgj"
   },
   "source": [
    "We pick the index which the models gives maximum probability to. This is the class ID that we take since we anyway know that the final vector should be one-hot. We compare this with target index (the index to which we have 1 in one-hot vector) and find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3wSYgf4lXIAM",
    "outputId": "576c5466-1af1-43e7-cdd7-2d02af380d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 4.146341463414634\n"
     ]
    }
   ],
   "source": [
    "fin_corr = []\n",
    "y = 0\n",
    "for i in range(10): \n",
    "  correct = 0\n",
    "  for output, label in zip(test_outputs, test_target):\n",
    "    y += 1 \n",
    "    label = label.reshape(-1,)\n",
    "    _, target = label.max(dim=0) #changing class ID \n",
    "    _, output = output.max(dim=0) #changing to class ID\n",
    "    if target == output:\n",
    "      correct += 1\n",
    "  fin_corr.append(correct)\n",
    "print(\"Accuracy\", (np.mean(np.array(fin_corr))/y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXEtMcVeNN8m"
   },
   "source": [
    "## RNN\n",
    "### RNN Architecture \n",
    "- We have 3 layers of RNN stacked up on top of each other \n",
    "- We then have a linear fully connected (FC) connected layer \n",
    "- Before the output layer we perform softmax. \n",
    "- Our input and output sizes are 101 corresponding to our one-hot sized vectors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ikaKzR0X59g"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=101, hidden_layer_size=150, output_size=101, num_layers = 3):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(3,1,self.hidden_layer_size))\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        rnn_out, self.hidden_cell = self.rnn(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.soft(self.linear(rnn_out.view(len(input_seq), -1)))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hf76ivE1ORM3"
   },
   "source": [
    "- We choose MSE loss \n",
    "- Optimiser is Adam \n",
    "- Learning rate is $2*10^{-8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFFbK_pcanDC"
   },
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2*10e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnEKdIOaO-LM"
   },
   "source": [
    "### Train the Model \n",
    "- We run this model for 50 epochs. In each epoch, all sequences are passed through one at a time\n",
    "- We compute gradient descent and perform backpropagation in each epoch to reduce the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "X1LZy8ecawMr",
    "outputId": "447d56cb-d4f5-4d6c-db3e-77745beb74b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([1, 101])) that is different to the input size (torch.Size([101])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.00978020\n",
      "epoch:   1 loss: 0.00976422\n",
      "epoch:   2 loss: 0.00974479\n",
      "epoch:   3 loss: 0.00971984\n",
      "epoch:   4 loss: 0.00968565\n",
      "epoch:   5 loss: 0.00963574\n",
      "epoch:   6 loss: 0.00955887\n",
      "epoch:   7 loss: 0.00943568\n",
      "epoch:   8 loss: 0.00923420\n",
      "epoch:   9 loss: 0.00891251\n",
      "epoch:  10 loss: 0.00843533\n",
      "epoch:  11 loss: 0.00780594\n",
      "epoch:  12 loss: 0.00708869\n",
      "epoch:  13 loss: 0.00638575\n",
      "epoch:  14 loss: 0.00578690\n",
      "epoch:  15 loss: 0.00533642\n",
      "epoch:  16 loss: 0.00503789\n",
      "epoch:  17 loss: 0.00487675\n",
      "epoch:  18 loss: 0.00483578\n",
      "epoch:  19 loss: 0.00490337\n",
      "epoch:  20 loss: 0.00507412\n",
      "epoch:  21 loss: 0.00534681\n",
      "epoch:  22 loss: 0.00572386\n",
      "epoch:  23 loss: 0.00620854\n",
      "epoch:  24 loss: 0.00679219\n",
      "epoch:  25 loss: 0.00743199\n",
      "epoch:  26 loss: 0.00804193\n",
      "epoch:  27 loss: 0.00853340\n",
      "epoch:  28 loss: 0.00887816\n",
      "epoch:  29 loss: 0.00910441\n",
      "epoch:  30 loss: 0.00925166\n",
      "epoch:  31 loss: 0.00934899\n",
      "epoch:  32 loss: 0.00941468\n",
      "epoch:  33 loss: 0.00945976\n",
      "epoch:  34 loss: 0.00949091\n",
      "epoch:  35 loss: 0.00951232\n",
      "epoch:  36 loss: 0.00952680\n",
      "epoch:  37 loss: 0.00953621\n",
      "epoch:  38 loss: 0.00954184\n",
      "epoch:  39 loss: 0.00954465\n",
      "epoch:  40 loss: 0.00954528\n",
      "epoch:  41 loss: 0.00954426\n",
      "epoch:  42 loss: 0.00954195\n",
      "epoch:  43 loss: 0.00953863\n",
      "epoch:  44 loss: 0.00953453\n",
      "epoch:  45 loss: 0.00952985\n",
      "epoch:  46 loss: 0.00952472\n",
      "epoch:  47 loss: 0.00951927\n",
      "epoch:  48 loss: 0.00951360\n",
      "epoch:  49 loss: 0.00950781\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "loss_epoch = []\n",
    "index = []\n",
    "for i in range(epochs): \n",
    "    index.append(i)\n",
    "    for seq, labels in zip(train_input, train_target):\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(3, 1, model.hidden_layer_size))\n",
    "        # print(np.shape(seq))\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_epoch.append(single_loss.item()) # Each epoch has 10 sequences. So printing after epoch for better representation. Talk abotu multi-dirac \n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAjYH02vPvLF"
   },
   "source": [
    "We plot epoch vs loss curve here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "nSqTmbzSI2wb",
    "outputId": "02e650be-b992-4893-a478-966716c9e9ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f51c51d9a90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(index, loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72a55OAPP8l-"
   },
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcPE9HRRbH3T"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_outputs = []\n",
    "for seq in test_input:\n",
    "  with torch.no_grad():\n",
    "        model.hidden_cell = (torch.zeros(3, 1, model.hidden_layer_size))\n",
    "        seq = seq.float()\n",
    "        seq= Variable(seq)\n",
    "        y_pred = model(seq)\n",
    "        test_outputs.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atKkmes0RFZo"
   },
   "source": [
    "We pick the index which the models gives maximum probability to. This is the class ID that we take since we anyway know that the final vector should be one-hot. We compare this with target index (the index to which we have 1 in one-hot vector) and find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hPp4lsD4b4Bw",
    "outputId": "9b5518c4-b6bd-4a7d-d0b7-ebe94cdb07bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 4.202961672473868\n"
     ]
    }
   ],
   "source": [
    "fin_corr = []\n",
    "y = 0\n",
    "for i in range(10): \n",
    "  correct = 0\n",
    "  for output, label in zip(test_outputs, test_target):\n",
    "    y += 1 \n",
    "    label = label.reshape(-1,)\n",
    "    _, target = label.max(dim=0) #changing class ID \n",
    "    _, output = output.max(dim=0) #changing to class ID\n",
    "    if target == output:\n",
    "      correct += 1\n",
    "  fin_corr.append(correct)\n",
    "print(\"Accuracy\", (np.mean(np.array(fin_corr))/y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN seems to have some oscillation in the loss. Higher epochs will confirm this. But no such indication for LSTM model. Higher epochs will confirm this. RNN model performs slightly better owing to its epochs but if the epochs were same LSTM might have the edge. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL Ass4 Q4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
